print(cm)
#newly split data logistic regression
cols <- c("Log_GDP", "Social_support", "Life_expectancy", "Freedom_of_choices", "Generosity", "Corruption", "Dystopia_and_residual")
predictors <- paste(cols, collapse = " + ")
log_formula <- as.formula(paste("Top_20 ~", predictors))
log_formula
# Train logistic regression model **on test_data**
logmodel_test <- glm(log_formula, data = test_data, family = "binomial")
# Predict on the same test_data
probs_test <- predict(logmodel_test, newdata = test_data, type = "response")
preds_test <- ifelse(probs_test > 0.5, 1, 0)
# Add predictions to the test_data frame
test_data$preds <- preds_test
# Evaluate model on test_data
actual_test <- factor(test_data$Top_20, levels = c(0, 1))
predicted_test <- factor(test_data$preds, levels = c(0, 1))
# Confusion Matrix
cm_test <- confusionMatrix(predicted_test, actual_test)
print(cm_test)
#newly split data logistic regression
train_data <- subset(happiness_data, Year < 2022)
test_data <- subset(happiness_data, Year >= 2022)
cols <- c("Log_GDP", "Social_support", "Life_expectancy", "Freedom_of_choices", "Generosity", "Corruption", "Dystopia_and_residual")
predictors <- paste(cols, collapse = " + ")
log_formula <- as.formula(paste("Top_20 ~", predictors))
log_formula
# Train logistic regression model **on test_data**
logmodel_test <- glm(log_formula, data = test_data, family = "binomial")
# Predict on the same test_data
probs_test <- predict(logmodel_test, newdata = test_data, type = "response")
preds_test <- ifelse(probs_test > 0.5, 1, 0)
# Add predictions to the test_data frame
test_data$preds <- preds_test
# Evaluate model on test_data
actual_test <- factor(test_data$Top_20, levels = c(0, 1))
predicted_test <- factor(test_data$preds, levels = c(0, 1))
# Confusion Matrix
cm_test <- confusionMatrix(predicted_test, actual_test)
print(cm_test)
null_countries = c("Angola", "Bhutan", "Syria", "Djibouti", "Oman", "Guyana", "Puerto Rico", "Qatar", "Somaliland Region", "Suriname", "Sudan", "Syria")
happiness_data<-happiness_data %>% filter(!(Country_name %in% null_countries))
# happiness_data
#newly split data logistic regression
train_data <- subset(happiness_data, Year < 2022)
test_data <- subset(happiness_data, Year >= 2022)
cols <- c("Log_GDP", "Social_support", "Life_expectancy", "Freedom_of_choices", "Generosity", "Corruption", "Dystopia_and_residual")
predictors <- paste(cols, collapse = " + ")
log_formula <- as.formula(paste("Top_20 ~", predictors))
log_formula
# Train logistic regression model **on test_data**
logmodel_test <- glm(log_formula, data = test_data, family = "binomial")
# Predict on the same test_data
probs_test <- predict(logmodel_test, newdata = test_data, type = "response")
preds_test <- ifelse(probs_test > 0.5, 1, 0)
# Add predictions to the test_data frame
test_data$preds <- preds_test
# Evaluate model on test_data
actual_test <- factor(test_data$Top_20, levels = c(0, 1))
predicted_test <- factor(test_data$preds, levels = c(0, 1))
# Confusion Matrix
cm_test <- confusionMatrix(predicted_test, actual_test)
print(cm_test)
library(dplyr)
library(caret)
null_countries <- c("Angola", "Bhutan", "Syria", "Djibouti", "Oman", "Guyana",
"Puerto Rico", "Qatar", "Somaliland Region", "Suriname", "Sudan", "Syria")
happiness_data <- happiness_data %>%
filter(!(Country_name %in% null_countries))
# Split the data
train_data <- subset(happiness_data, Year < 2022)
test_data <- subset(happiness_data, Year >= 2022)
# Ensure Top_20 is binary
test_data$Top_20 <- as.integer(test_data$Top_20 == TRUE)
# Define model formula
cols <- c("Log_GDP", "Social_support", "Life_expectancy",
"Freedom_of_choices", "Generosity",
"Corruption", "Dystopia_and_residual")
predictors <- paste(cols, collapse = " + ")
log_formula <- as.formula(paste("Top_20 ~", predictors))
# Fit logistic regression on test_data
logmodel_test <- glm(log_formula, data = test_data, family = "binomial")
# Predict and classify
probs_test <- predict(logmodel_test, newdata = test_data, type = "response")
preds_test <- ifelse(probs_test > 0.5, 1, 0)
test_data$preds <- preds_test
# Evaluate with confusion matrix
actual_test <- factor(test_data$Top_20, levels = c(0, 1))
predicted_test <- factor(test_data$preds, levels = c(0, 1))
cm_test <- confusionMatrix(predicted_test, actual_test)
print(cm_test)
# Load required libraries
library(dplyr)
library(caret)
# Optional: Remove countries with missing/incomplete data
null_countries <- c("Angola", "Bhutan", "Syria", "Djibouti", "Oman", "Guyana",
"Puerto Rico", "Qatar", "Somaliland Region", "Suriname", "Sudan", "Syria")
happiness_data <- happiness_data %>%
filter(!(Country_name %in% null_countries))
# Split data by year
train_data <- subset(happiness_data, Year < 2022)
test_data <- subset(happiness_data, Year >= 2022)
# Ensure binary format for Top_20 in both datasets
train_data$Top_20 <- as.integer(train_data$Top_20 == TRUE)
test_data$Top_20 <- as.integer(test_data$Top_20 == TRUE)
# Define predictor columns
cols <- c("Log_GDP", "Social_support", "Life_expectancy",
"Freedom_of_choices", "Generosity",
"Corruption", "Dystopia_and_residual")
# Create formula dynamically
predictors <- paste(cols, collapse = " + ")
log_formula <- as.formula(paste("Top_20 ~", predictors))
# Train logistic regression on train_data
logmodel <- glm(log_formula, data = train_data, family = "binomial")
# Predict on test_data
probs <- predict(logmodel, newdata = test_data, type = "response")
preds <- ifelse(probs > 0.5, 1, 0)
# Add predictions to test_data
test_data$preds <- preds
# Create factors for evaluation
actual <- factor(test_data$Top_20, levels = c(0, 1))
predicted <- factor(test_data$preds, levels = c(0, 1))
# Confusion matrix
cm <- confusionMatrix(predicted, actual)
print(cm)
test_data$Top_20 <- as.factor(test_data$Top_20)
# Predict class labels (Top_20) for test_data
predictions <- predict(reduced_train_model, newdata = test_data, type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$Top_20)
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Test Accuracy:", round(accuracy, 4), "\n")
# Train the decision tree using rpart
#install.packages("rpart.plot")
library(rpart.plot)
reduced_train_model <- rpart(Top_20 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual+Top20_Last             ,data = train_data, method = "class")
rpart.plot(reduced_train_model)
reduced_train_model$variable.importance
test_data$Top_20 <- as.factor(test_data$Top_20)
# Predict class labels (Top_20) for test_data
predictions <- predict(reduced_train_model, newdata = test_data, type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$Top_20)
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Test Accuracy:", round(accuracy, 4), "\n")
# Train the decision tree using rpart
#install.packages("rpart.plot")
library(rpart.plot)
reduced_train_model <- rpart(Top_20 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual+Top20_Last             ,data = train_data, method = "class")
rpart.plot(reduced_train_model)
reduced_train_model$variable.importance
# Train the decision tree using rpart
library(rpart)
reduced_train_model_20 <- rpart(Top_20 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual             ,data = train_data, method = "class")
rpart.plot(reduced_train_model_20)
reduced_train_model$variable.importance
# Train the decision tree using rpart
library(rpart)
reduced_train_model_20 <- rpart(Top_20 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual             ,data = train_data, method = "class")
rpart.plot(reduced_train_model_20)
reduced_train_model$variable.importance
# Train the decision tree using rpart
library(rpart)
reduced_train_model_20 <- rpart(Top_20 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual             ,data = train_data, method = "class")
rpart.plot(reduced_train_model_20)
reduced_train_model_20$variable.importance
test_data$Top_20 <- as.factor(test_data$Top_20)
# Predict class labels (Top_20) for test_data
predictions <- predict(reduced_train_model_20, newdata = test_data, type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$Top_20)
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Test Accuracy:", round(accuracy, 4), "\n")
# Train the decision tree using rpart
#install.packages("rpart.plot")
library(rpart.plot)
reduced_train_model_2 <- rpart(Top_20 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual+Top20_Last             ,data = train_data_rand, method = "class")
rpart.plot(reduced_train_model_2)
reduced_train_model_2$variable.importance
test_data_rand$Top_20 <- as.factor(test_data_rand$Top_20)
# Predict class labels (Top_20) for test_data
predictions <- predict(reduced_train_model_2, newdata = test_data, type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$Top_20)
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Test Accuracy:", round(accuracy, 4), "\n")
# Train the decision tree using rpart
library(rpart)
reduced_train_model_202 <- rpart(Top_20 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual             ,data = train_data_rand, method = "class")
rpart.plot(reduced_train_model_202)
reduced_train_model_202$variable.importance
test_data_rand$Top_20 <- as.factor(test_data_rand$Top_20)
# Predict class labels (Top_20) for test_data
predictions <- predict(reduced_train_model_202, newdata = test_data, type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$Top_20)
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Test Accuracy:", round(accuracy, 4), "\n")
## removing null countries
null_countries = c("Angola", "Bhutan", "Syria", "Djibouti", "Oman", "Guyana", "Puerto Rico", "Qatar", "Somaliland Region", "Suriname", "Sudan", "Syria")
happiness_data<-happiness_data %>% filter(!(Country_name %in% null_countries))
# happiness_data
## logistic regression example
set.seed(123)
# renamed to Corruption for simplicity.
# happiness_data <- happiness_data %>% rename(Corruption = `Explained by: Perceptions of corruption`)
happiness_data <- happiness_data[sample(nrow(happiness_data)), ]
sample <- sample(c(TRUE, FALSE), nrow(happiness_data), replace=TRUE, prob=c(0.8,0.2))
train  <- happiness_data[sample, ]
test   <- happiness_data[!sample, ]
cols <- c("Log_GDP", "Social_support", "Life_expectancy", "Freedom_of_choices", "Generosity", "Corruption", "Dystopia_and_residual")
predictors <- paste(cols, collapse = " + ")
log_formula <- as.formula(paste("Top_20 ~", predictors))
log_formula
logmodel <- glm(log_formula,
data = train, family = "binomial")
#summary(logmodel)
probs <- predict(logmodel, newdata = test, type = "response")
preds <- ifelse(probs > 0.5, 1, 0)
test$Top_20 <- as.integer(test$Top_20 == TRUE)
test$preds <- preds
actual <- factor(test$Top_20, levels = c(0, 1))
predicted <- factor(test$preds, levels = c(0, 1))
cm <- confusionMatrix(predicted, actual)
print(cm)
# Load required libraries
library(dplyr)
library(caret)
# Optional: Remove countries with missing/incomplete data
null_countries <- c("Angola", "Bhutan", "Syria", "Djibouti", "Oman", "Guyana",
"Puerto Rico", "Qatar", "Somaliland Region", "Suriname", "Sudan", "Syria")
happiness_data <- happiness_data %>%
filter(!(Country_name %in% null_countries))
# Split data by year
train_data <- subset(happiness_data, Year < 2022)
test_data <- subset(happiness_data, Year >= 2022)
# Ensure binary format for Top_20 in both datasets
train_data$Top_20 <- as.integer(train_data$Top_20 == TRUE)
test_data$Top_20 <- as.integer(test_data$Top_20 == TRUE)
# Define predictor columns
cols <- c("Log_GDP", "Social_support", "Life_expectancy",
"Freedom_of_choices", "Generosity",
"Corruption", "Dystopia_and_residual")
# Create formula dynamically
predictors <- paste(cols, collapse = " + ")
log_formula <- as.formula(paste("Top_20 ~", predictors))
# Train logistic regression on train_data
logmodel <- glm(log_formula, data = train_data, family = "binomial")
# Predict on test_data
probs <- predict(logmodel, newdata = test_data, type = "response")
preds <- ifelse(probs > 0.5, 1, 0)
# Add predictions to test_data
test_data$preds <- preds
# Create factors for evaluation
actual <- factor(test_data$Top_20, levels = c(0, 1))
predicted <- factor(test_data$preds, levels = c(0, 1))
# Confusion matrix
cm <- confusionMatrix(predicted, actual)
print(cm)
test_data$Top_20 <- as.factor(test_data$Top_20)
# Predict class labels (Top_20) for test_data
predictions <- predict(reduced_train_model_20, newdata = test_data, type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$Top_20)
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Test Accuracy:", round(accuracy, 4), "\n")
# Load required libraries
library(dplyr)
library(caret)
# Optional: Remove countries with missing/incomplete data
null_countries <- c("Angola", "Bhutan", "Syria", "Djibouti", "Oman", "Guyana",
"Puerto Rico", "Qatar", "Somaliland Region", "Suriname", "Sudan", "Syria")
happiness_data <- happiness_data %>%
filter(!(Country_name %in% null_countries))
set.seed(123)
happiness_data <- happiness_data[sample(nrow(happiness_data)), ]
sample <- sample(c(TRUE, FALSE), nrow(happiness_data), replace=TRUE, prob=c(0.8,0.2))
train  <- happiness_data[sample, ]
test   <- happiness_data[!sample, ]
cols <- c("Log_GDP", "Social_support", "Life_expectancy", "Freedom_of_choices", "Generosity", "Corruption", "Dystopia_and_residual")
predictors <- paste(cols, collapse = " + ")
log_formula <- as.formula(paste("Top_20 ~", predictors))
log_formula
logmodel <- glm(log_formula,
data = train, family = "binomial")
#summary(logmodel)
probs <- predict(logmodel, newdata = test, type = "response")
preds <- ifelse(probs > 0.5, 1, 0)
test$Top_20 <- as.integer(test$Top_20 == TRUE)
test$preds <- preds
actual <- factor(test$Top_20, levels = c(0, 1))
predicted <- factor(test$preds, levels = c(0, 1))
cm <- confusionMatrix(predicted, actual)
print(cm)
# Split data by year
train_data <- subset(happiness_data, Year < 2022)
test_data <- subset(happiness_data, Year >= 2022)
# Ensure binary format for Top_20 in both datasets
train_data$Top_20 <- as.integer(train_data$Top_20 == TRUE)
test_data$Top_20 <- as.integer(test_data$Top_20 == TRUE)
# Define predictor columns
cols <- c("Log_GDP", "Social_support", "Life_expectancy",
"Freedom_of_choices", "Generosity",
"Corruption", "Dystopia_and_residual")
# Create formula dynamically
predictors <- paste(cols, collapse = " + ")
log_formula <- as.formula(paste("Top_20 ~", predictors))
# Train logistic regression on train_data
logmodel <- glm(log_formula, data = train_data, family = "binomial")
# Predict on test_data
probs <- predict(logmodel, newdata = test_data, type = "response")
preds <- ifelse(probs > 0.5, 1, 0)
# Add predictions to test_data
test_data$preds <- preds
# Create factors for evaluation
actual <- factor(test_data$Top_20, levels = c(0, 1))
predicted <- factor(test_data$preds, levels = c(0, 1))
# Confusion matrix
cm <- confusionMatrix(predicted, actual)
print(cm)
test_data_chron$Top_20 <- as.factor(test_data_chron$Top_20)
# Split data
train_data_chron <- subset(happiness_data, Year < 2022)
test_data_chron <- subset(happiness_data, Year >= 2022)
test_data_chron$Top_20 <- as.factor(test_data_chron$Top_20)
# Predict class labels (Top_20) for test_data
predictions <- predict(first_tree_model, newdata = test_data, type = "class")
# Train the decision tree using rpart
#install.packages("rpart.plot")
library(rpart.plot)
first_tree_model <- rpart(Top_20 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual+Top20_Last             ,data = train_data_chron, method = "class")
rpart.plot(first_tree_model)
first_tree_model$variable.importance
test_data_chron$Top_20 <- as.factor(test_data_chron$Top_20)
# Predict class labels (Top_20) for test_data
predictions <- predict(first_tree_model, newdata = test_data, type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data_chron$Top_20)
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Test Accuracy:", round(accuracy, 4), "\n")
# Train the decision tree using rpart
library(rpart)
second_tree_model <- rpart(Top_20 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual             ,data = train_data_chron, method = "class")
rpart.plot(second_tree_model)
second_tree_model$variable.importance
test_data_chron$Top_20 <- as.factor(test_data_chron$Top_20)
# Predict class labels (Top_20) for test_data
predictions <- predict(second_tree_model, newdata = test_data_chron, type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data_chron$Top_20)
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Test Accuracy:", round(accuracy, 4), "\n")
happiness_data <- happiness_data[sample(nrow(happiness_data)), ]#take the happiness data
sample <- sample(c(TRUE, FALSE), nrow(happiness_data), replace=TRUE, prob=c(0.8,0.2))# split the data 80-20
train_data_rand  <- happiness_data[sample, ]
test_data_rand   <- happiness_data[!sample, ]
test_data_chron$Top_20 <- as.factor(test_data_chron$Top_20)
# Predict class labels (Top_20) for test_data
predictions <- predict(second_tree_model, newdata = test_data_chron, type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data_chron$Top_20)
print(conf_matrix)
# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Test Accuracy:", round(accuracy, 4), "\n")
set.seed(123)
happiness_data <- happiness_data[sample(nrow(happiness_data)), ]
sample <- sample(c(TRUE, FALSE), nrow(happiness_data), replace=TRUE, prob=c(0.8,0.2))
train  <- happiness_data[sample, ]
test   <- happiness_data[!sample, ]
cols <- c("Log_GDP", "Social_support", "Life_expectancy", "Freedom_of_choices", "Generosity", "Corruption", "Dystopia_and_residual")
predictors <- paste(cols, collapse = " + ")
log_formula <- as.formula(paste("Top_20 ~", predictors))
log_formula
logmodel <- glm(log_formula,
data = train, family = "binomial")
probs <- predict(logmodel, newdata = test, type = "response")
preds <- ifelse(probs > 0.5, 1, 0)
test$Top_20 <- as.integer(test$Top_20 == TRUE)
test$preds <- preds
actual <- factor(test$Top_20, levels = c(0, 1))
predicted <- factor(test$preds, levels = c(0, 1))
cm <- confusionMatrix(predicted, actual)
print(cm)
# Train the decision tree using rpart
second_tree_model <- rpart(Top_20 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual             ,data = train_data_chron, method = "class")
rpart.plot(second_tree_model)
second_tree_model$variable.importance
first_tree_model <- (Top_15 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual , data = train_data_chron , method = "class")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(dplyr)
library(stringr)
library(ggplot2)
library(patchwork)
library(caret)
library(pROC)
library(rpart.plot)
library(readxl)  # a libary for loading excel files
happiness_data <- read_csv("happiness_data_clean_2011_2024.csv")#load data
happiness_data <- happiness_data %>%
mutate(`Country name` = trimws(`Country name`))
happiness_data <- happiness_data %>%
group_by(`Country name`) %>%
fill(
`Ladder score`, upperwhisker, lowerwhisker,
`Explained by: Log GDP per capita`, `Explained by: Social support`,
`Explained by: Healthy life expectancy`, `Explained by: Freedom to make life choices`,
`Explained by: Generosity`, `Explained by: Perceptions of corruption`,
`Dystopia + residual`,
.direction = "downup"
) %>%
ungroup()
# erasure of non existent countries
happiness_data <- happiness_data %>%
filter(!is.na(`Ladder score`)) # use only complete data(without null values)
happiness_data <- read_csv("happiness_data_clean_2011_2024.csv")#load data
happiness_data <- happiness_data %>%
mutate(`Country name` = trimws(`Country name`))
happiness_data <- happiness_data %>%
group_by(`Country name`) %>%
fill(
`Ladder score`, upperwhisker, lowerwhisker,
`Explained by: Log GDP per capita`, `Explained by: Social support`,
`Explained by: Healthy life expectancy`, `Explained by: Freedom to make life choices`,
`Explained by: Generosity`, `Explained by: Perceptions of corruption`,
`Dystopia + residual`,
.direction = "downup"
) %>%
ungroup()
# erasure of non existent countries
happiness_data <- happiness_data %>%
filter(!is.na(`Ladder score`)) # use only complete data(without null values)
happiness_data <- happiness_data %>%
group_by(Year) %>%
mutate(Top_20 = Rank <= 20) %>%# create a new top_20 column
mutate(Top_20 = Rank <= 15) %>%# create a new top_15 column
mutate(Top_20 = Rank <= 25) %>%# create a new top_25 column
ungroup() %>%
#renaming the column in order to be usable in R
rename(Country_name = `Country name`, Ladder_score = `Ladder score`, Log_GDP = `Explained by: Log GDP per capita`, Social_support = `Explained by: Social support`, Life_expectancy = `Explained by: Healthy life expectancy`, Freedom_of_choices = `Explained by: Freedom to make life choices`, Generosity = `Explained by: Generosity`, Dystopia_and_residual = `Dystopia + residual`, Corruption = `Explained by: Perceptions of corruption` )
happiness_data <- happiness_data %>%
arrange(Country_name, Year) %>%  # Sort by country and year
group_by(Country_name) %>%      # Process each country separately
mutate(Top20_Last = lag(Top_20)) %>%  # Get last year's Top_20 and create new column
ungroup() %>%  # Remove grouping
mutate(Top20_Last = case_when(
is.na(Top20_Last) ~ 2,         # No previous data
Top20_Last == 1 ~ 1,           # Was in top 20
Top20_Last == 0 ~ 0            # Was not in top 20
))
# count Top_20 appearences by country
top_countries_long <- happiness_data %>%
filter(Top_20) %>%
count(Country_name, name = "Years_in_Top_20") %>%
arrange(desc(Years_in_Top_20))
tpl1 <- top_countries_long %>%
filter(Years_in_Top_20 >= 5) %>%
ggplot(aes(x = reorder(Country_name, Years_in_Top_20), y = Years_in_Top_20)) +
geom_col(fill = "lightgreen") +
coord_flip() +
labs(
title = "Number of Years Each Country was in the Top 20",
x = "Country",
y = "Years in Top 20"
) +
theme_minimal(base_size = 13) +
theme(
plot.title = element_text(size = 16, face = "bold"),
axis.text = element_text(size = 12),
axis.title = element_text(size = 13)
)
plt1 <- ggplot(happiness_data, aes(x = Social_support, y = Ladder_score)) +
geom_point(alpha=0.4) +
geom_smooth(method="lm", se=FALSE, color="blue") +
labs(title="Ladder score vs Social support")
plt <- ggplot(happiness_data, aes(x=Rank)) + geom_histogram(color="darkblue", fill="lightblue", binwidth=3) +
labs(title="Distribution of rankings")+
theme_minimal(base_size = 13) +
theme(
plot.title = element_text(size = 12, face = "bold"),
axis.text = element_text(size = 12),
axis.title = element_text(size = 13)
)
# Split data
train_data_chron <- subset(happiness_data, Year < 2022)
test_data_chron <- subset(happiness_data, Year >= 2022)
first_tree_model <- (Top_15 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual             ,data = train_data_chron, method = "class")
first_tree_model <- (Top_15 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual,data = train_data_chron,method = "class")
first_tree_model <- (Top_15 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual,data = train_data_chron , method = "class")
first_tree_model <-(Top_15 ~  Year +  Log_GDP + Social_support + Life_expectancy +  Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual,data = train_data_chron , method = "class")
first_tree_model <- rpart(
Top_15 ~ Year + Log_GDP + Social_support + Life_expectancy +
Freedom_of_choices + Generosity + Corruption + Dystopia_and_residual,
data = train_data_chron,
method = "class"
)
